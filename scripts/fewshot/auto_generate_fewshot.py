#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Few-shot è‡ªå‹•ç”Ÿæˆï¼ˆSQLite ç‰ˆæœ¬ï¼‰
=====================================================
ç¬¦åˆä½ çš„è¦å‰‡ï¼š

1. åš´æ ¼ä¾ SQLite PRAGMA å¤–éµåˆ—è¡¨ï¼Œä¸æ¨è«–ã€ä¸çŒœæ¸¬ã€ä¸å¯«æ­» FKã€‚
2. åªä½¿ç”¨ PRAGMA å¤–éµæ§‹å»º JOIN åœ–ï¼ˆç„¡å‘åœ–ï¼‰â†’ BFS â†’ JOIN Routeã€‚
3. SELECT ä¸€å¾‹ï¼š  t0.*, t1.*, t2.* ...
4. WHERE å­å¥ï¼š
   - æ°¸é ä½¿ç”¨ root table alias = t0
   - TEXT æ¬„ä½ï¼šLIKE '%value%'
   - é TEXTï¼š= value
   - NULL ä¸åŠ å…¥ WHERE
5. SQL å…ˆä»¥ SQLite execute é©—è­‰ï¼ŒéŒ¯èª¤å³è·³éã€‚
6. æ¯å¼µè¡¨ç”¢ç”Ÿ 1 ç­† few-shotã€‚
7. è¼¸å‡ºæ ¼å¼èˆ‡ä½ åŸç³»çµ±å®Œå…¨ä¸€è‡´ï¼š
   { extract: {}, parse: {}, questions: [ ... ] }
"""

import sqlite3
import json
import os
import argparse
from pathlib import Path
import sys

# === æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘ ===
from pathlib import Path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'src'))

from runner.logger import Logger
from llm.model import model_chose


# =====================================================
#  å–å¾— SQLite Schema
# =====================================================
def analyze_database(db_path):
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()

    # æ‰€æœ‰ table
    cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';")
    tables = [r[0] for r in cur.fetchall()]

    schema = {}
    for t in tables:
        cur.execute(f"PRAGMA table_info('{t}');")
        cols = cur.fetchall()

        cur.execute(f"PRAGMA foreign_key_list('{t}');")
        fks = cur.fetchall()

        schema[t] = {
            "columns": cols,
            "fks": fks
        }

    conn.close()
    return tables, schema


# =====================================================
#  å»º FK Graphï¼ˆç„¡å‘åœ–ï¼‰
# =====================================================
def build_fk_graph(tables, schema):
    graph = {t: [] for t in tables}

    for t in tables:
        for fk in schema[t]["fks"]:
            # (id, seq, ref_table, from_col, to_col, ...)
            ref_table = fk[2]
            from_col = fk[3]
            to_col = fk[4]

            if ref_table in graph:
                graph[t].append((ref_table, from_col, to_col))
                graph[ref_table].append((t, to_col, from_col))  # ç„¡å‘

    return graph


# =====================================================
#  BFS å–å¾— JOIN é †åº
# =====================================================
def bfs_join_tables(root, graph):
    visited = set()
    queue = [root]
    order = []

    while queue:
        t = queue.pop(0)
        if t in visited:
            continue
        visited.add(t)
        order.append(t)

        for (to_table, _, _) in graph[t]:
            if to_table not in visited:
                queue.append(to_table)

    return order


# =====================================================
# å– sample row
# =====================================================
def get_sample_row(db_path, table):
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()

    try:
        cur.execute(f"SELECT * FROM {table} LIMIT 1;")
        row = cur.fetchone()
        if row is None:
            conn.close()
            return None

        cols = [c[0] for c in cur.description]
        conn.close()
        return dict(zip(cols, row))

    except:
        conn.close()
        return None


# =====================================================
# WHERE å­å¥ç”Ÿæˆï¼ˆä½ çš„è¦å‰‡ï¼‰
# =====================================================
def build_where_clause_text(value):
    safe = value.replace("'", "''")
    return f"LIKE '%{safe}%'"


def build_where_clause(sample_row, schema_cols):
    parts = []
    for colinfo in schema_cols:
        col_name = colinfo[1]
        col_type = colinfo[2]
        val = sample_row.get(col_name)

        if val is None:
            continue

        if isinstance(val, str):
            parts.append(f"t0.{col_name} {build_where_clause_text(val)}")
        else:
            parts.append(f"t0.{col_name} = {val}")

    if not parts:
        return ""
    return "WHERE " + " AND ".join(parts)


# =====================================================
# JOIN SQL ç”Ÿæˆ
# =====================================================
def generate_join_sql(root, join_order, schema, graph, sample_row):
    # æ¯å€‹ table åˆ†é… alias
    aliases = {t: f"t{i}" for i, t in enumerate(join_order)}

    sql_lines = []

    # SELECT
    select_parts = [f"{aliases[t]}.*" for t in join_order]
    sql_lines.append(f"SELECT {', '.join(select_parts)}")

    # FROM root
    sql_lines.append(f"FROM {root} {aliases[root]}")

    # JOIN å…¶ä»– tableï¼ˆä¾ BFS é †åºå»º parentï¼‰
    for t in join_order:
        if t == root:
            continue

        # æ‰¾ parent
        parent = None
        parent_fk = None

        for pt in join_order:
            if pt == t:
                break
            for (to_table, from_col, to_col) in graph[pt]:
                if to_table == t:
                    parent = pt
                    parent_fk = (from_col, to_col)
                    break
            if parent:
                break

        if not parent:
            continue

        p_alias = aliases[parent]
        t_alias = aliases[t]
        from_col, to_col = parent_fk

        sql_lines.append(
            f"LEFT JOIN {t} {t_alias} ON {p_alias}.{from_col} = {t_alias}.{to_col}"
        )

    # WHEREï¼ˆåªç”¨ root t0ï¼‰
    root_cols = schema[root]["columns"]
    where_sql = build_where_clause(sample_row, root_cols)
    if where_sql:
        sql_lines.append(where_sql)

    sql_lines.append("LIMIT 200;")

    return "\n".join(sql_lines)


# =====================================================
# SQL é©—è­‰
# =====================================================
def validate_sql(db_path, sql):
    try:
        conn = sqlite3.connect(db_path)
        cur = conn.cursor()
        cur.execute(sql)
        cur.fetchall()
        conn.close()
        return True
    except Exception as e:
        print("   âŒ SQL failed:", e)
        return False


# =====================================================
# LLM ç”¢ç”Ÿ question
# =====================================================
def llm_generate_question(model, sql):
    prompt = (
        "è«‹æ ¹æ“šä»¥ä¸‹ SQL æŸ¥è©¢å…§å®¹ï¼Œä»¥ä¸æ¨è«–ã€ä¸è‡ªè¡Œå»¶ä¼¸ã€ä¸åŠ å…¥æ¨æ¸¬èªæ„ç‚ºå‰æï¼Œ"
        "ç”¨è‡ªç„¶çš„ç¹é«”ä¸­æ–‡å¯«å‡ºã€Œé€™æ®µ SQL çš„æŸ¥è©¢å•é¡Œæ•˜è¿°ã€ã€‚è«‹å°ˆæ³¨ SQL å¯¦éš›å…§å®¹ã€‚\n\n"
        f"SQL:\n{sql}\n\nè«‹åªè¼¸å‡ºå•é¡Œï¼š"
    )

    res = model.get_ans(prompt, temperature=0)
    if not res:
        return "æŸ¥è©¢è³‡æ–™"
    return res.strip()


# =====================================================
# Schema textï¼ˆç”¨æ–¼ promptï¼‰
# =====================================================
def generate_schema_description(schema):
    lines = ["/* çµ¦å®šä»¥ä¸‹è³‡æ–™åº« schema: */\n"]

    for t, info in schema.items():
        lines.append(f"-- {t}")
        lines.append("CREATE TABLE %s (" % t)

        col_defs = []
        for col in info["columns"]:
            cname = col[1]
            ctype = col[2]
            col_defs.append(f"  {cname} {ctype}")
        lines.append(",\n".join(col_defs))
        lines.append(");\n")

        # å¤–éµ
        if info["fks"]:
            lines.append("/* FOREIGN KEYS:")
            for fk in info["fks"]:
                lines.append(f" * {t}.{fk[3]} -> {fk[2]}.{fk[4]}")
            lines.append(" */\n")

    return "\n".join(lines)


# =====================================================
# ç‚º table ç”¢ç”Ÿ few-shot
# =====================================================
def generate_fewshot_for_table(table, db_path, schema, graph, model, db_name):
    print(f"\nğŸ§© è™•ç† table: {table}")

    sample = get_sample_row(db_path, table)
    if not sample:
        print("   âš ï¸ ç„¡è³‡æ–™ï¼Œè·³é")
        return None

    join_order = bfs_join_tables(table, graph)

    sql = generate_join_sql(table, join_order, schema, graph, sample)

    if not validate_sql(db_path, sql):
        return None

    question = llm_generate_question(model, sql)

    schema_desc = generate_schema_description(schema)
    full_prompt = f"{schema_desc}\n\n/* å›ç­”ä»¥ä¸‹å•é¡Œï¼š{question} */\n{sql}"

    return {
        "question": question,
        "db_id": db_name,
        "prompt": full_prompt
    }


# =====================================================
# main()
# =====================================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--db_root_directory", type=str, required=True)
    parser.add_argument("--model", type=str, default="gpt-4o")
    args = parser.parse_args()

    db_name = args.db_root_directory
    db_path = f"{db_name}/dev/dev_databases/{db_name}/{db_name}.sqlite"

    if not os.path.exists(db_path):
        print(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™åº«ï¼š{db_path}")
        return

    _logger = Logger(db_id="auto_fewshot", question_id=0, result_directory="logs")

    print("ğŸ”§ åˆå§‹åŒ– LLM...")
    model = model_chose("auto_fewshot", args.model)

    print("ğŸ“Š è®€å– SQLite schema...")
    tables, schema = analyze_database(db_path)

    print("ğŸ”— å»ºç«‹ FK Graph...")
    graph = build_fk_graph(tables, schema)

    fewshots = []

    print("\nğŸš€ é–‹å§‹ç”Ÿæˆ few-shot...")
    for t in tables:
        fs = generate_fewshot_for_table(t, db_path, schema, graph, model, db_name)
        if fs:
            fewshots.append(fs)

    # output
    output_path = Path(db_name) / "fewshot" / "questions.json"
    output_path.parent.mkdir(parents=True, exist_ok=True)

    data = {
        "extract": {},
        "parse": {},
        "questions": fewshots
    }

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ å®Œæˆï¼few-shot å·²è¼¸å‡ºåˆ°: {output_path}")
    print(f"âœ” ç”¢ç”Ÿ {len(fewshots)} ç­† few-shot")


if __name__ == "__main__":
    main()
